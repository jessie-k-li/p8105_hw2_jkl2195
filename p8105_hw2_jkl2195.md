p8105_hw2_jkl2195
================
Jessie Li
2023-10-01

Import datasets

``` r
df_pols_month = read.csv("data/pols-month.csv",)
df_unemployment = read.csv("data/unemployment.csv")
df_snp = read.csv("data/snp.csv")
```

## Problem 1

Clean up pols-month.csv

``` r
df_pols_month = df_pols_month |>
  separate(mon, c("year", "month", "day"), "-", convert = TRUE)

df_pols_month = df_pols_month |>
  mutate(
    month = month.abb[as.numeric(pull(df_pols_month, "month"))],
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")
  )|>
  select(-prez_dem, -prez_gop, -day)# Convert month number to month name
```

Clean up snp.csv

``` r
df_snp = df_snp |>
  separate(date, c("month", "day", "year"), "/", convert = TRUE)  |>
  mutate(year = case_when((year < 24) ~ year + 2000,
                             TRUE ~ year + 1900))

df_snp = df_snp |>
  mutate(
    month = month.abb[as.numeric(pull(df_snp, "month"))]
  ) |>
  select(-day) |>
  arrange(year, month)
```

Clean up unemployment.csv

``` r
df_unemployment = df_unemployment |>
  rename(year = "Year") |>
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment_percent")
```

Merging snp and unemployment into pols

``` r
df_pols_snp_merged = df_pols_month |> 
  left_join(df_snp) |>
  left_join(df_unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

**Description**  
The resulting data set contains the party of the president and the
number of governors, senator, and representative in each party. There
are total of 822 of entries. The data range between 1947 to 2015 and is
organized by month. The data also indicate the closing values of the S&P
stock, a value that evaluates the economy at the point, and the
unemployment rate in percentage.

## Problem 2

``` r
df_mr_trash = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |>
  janitor::clean_names("snake") |>
  mutate(
    wheel = "Mr. Trash Wheel",
    year = as.numeric(year)
  ) |>
  select(-dumpster)

df_prof_trash = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |>
  janitor::clean_names("snake") |>
  mutate(
    wheel = "Professor Trash Wheel",
    year = as.numeric(year)
  ) |> 
  select(-dumpster)

df_gwynnda_trash = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>
  janitor::clean_names("snake") |>
  mutate(
    wheel = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  ) |>
  select(-dumpster)


df_trash_merged = df_mr_trash |>
  bind_rows(df_prof_trash, df_gwynnda_trash) |>
  mutate(
    homes_powered = if_else(homes_powered == 0, weight_tons / 30 * 500, homes_powered)
  )

df_trash_merged
```

    ## # A tibble: 845 × 14
    ##    month  year date                weight_tons volume_cubic_yards
    ##    <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, wheel <chr>

**Description**  
This dataset records the weight and volume of trash picked up by
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. Trash
is seperated to There are a total of 845. This dataset does not contain
the number of dumpster registered but keeps all the categories of the
waste. Some key categories includes the weight of plastic, number of
plastic bottles, and the weight of polystyrene. Gwynnda Trash Wheel have
missing values in categories plastic bottles, wrapper, home powered and
sports ball. Professor Trash Wheel having missing values in sports
balls. Mr Trash Wheel has some missing values in home powered variable.
Based on the note given by original dataset variable `homes_powered`
denotes each ton of trash equates to on average 500 kilowatts of
electricity. The home_powered for missing values are calculated with the
assumption an average household will use 30 kilowatts per day. The total
weight of trash collected by Professor Trash Wheel was 216.26 tons. The
total number of cigarette butts collected by Gwynnda in July of 2021 is
98300.

# Problem 3

**MCI Baseline**

``` r
df_mci_baseline = read_csv("data/MCI_baseline.csv", skip = 1, na = c(".", "NA")) |>
  janitor::clean_names("snake") |>
  mutate(
    sex = case_match(
      sex,
      0 ~ "female", 
      1 ~ "male"
      ),
    apoe4 = case_match(
      apoe4,
      0 ~ "non carrier",
      1 ~ "carrier"
    ),
    current_age = as.numeric(current_age),
    age_at_onset = as.numeric(age_at_onset)
  ) |>
  #Remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline)
  filter(current_age <= age_at_onset | is.na(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): ID, Current Age, Sex, Education, apoe4, Age at onset
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Description**  
The MCI baseline data set contains the demographics of individuals who
are likely to get Mild Cognitive Impairment of Alzheimer’s disease. The
Individuals are also recorded if they are a carrier of APOE4, a gene
that significantly associated with a higher risk of developing
Alzheimer’s disease. Demographics include ag e at the beginning of the
study, sex, and years of education. Sex and the appearence of APOE4 are
recoded to the corresponding index. Individuals that are already in Mild
Cognitive Impairment before the study are dropped. In total of 480
participants that are qualified, 94 individuals develop MCI? The average
baseline age is 65.0320833 The proportion of women in the study are
APOE4 carriers is 0.13125.

**MCI Amyloid**

``` r
# Both Na and NA is treated as missing value.
df_mci_amyloid = read_csv("data/mci_amyloid.csv", na = c("NA", "Na"), skip = 1) |>
  janitor::clean_names("snake") |>
  rename(
    id = study_id
  )
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): Study ID, Baseline, Time 2, Time 4, Time 6, Time 8
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Description**  
The MCI amyloid contains the study id of the individuals, time since the
beginning of the study to conduct Amyloid 42/40 testing, and biomarker
values at corresponding time.

**Compare demographic and biomarker datasets**  
The individuals with the following study id are only in
baseline/demographic dataset:

``` r
df_mci_baseline |> 
  select(id) |> 
  filter(!(id %in% pull(df_mci_amyloid, id))) |> 
  pull() |> 
  print()
```

    ## [1]  14  49  92 179 268 304 389 412

The individuals with the following study id are only in
amyloid/biomarker dataset:

``` r
df_mci_amyloid |> 
  select(id) |> 
  filter(!(id %in% pull(df_mci_baseline, id))) |> 
  pull() |> 
  print()
```

    ##  [1]  72 283 380 484 485 486 487 488 489 490 491 492 493 494 495

**Combine demographic and biomarker datasets and save them inside data
folder**

``` r
df_mci_merged = inner_join(df_mci_baseline, df_mci_amyloid)
```

    ## Joining with `by = join_by(id)`

``` r
write.csv("data/mci merged.csv", row.names = FALSE)
```

    ## "x"
    ## "data/mci merged.csv"

**Description**  
The combined data consist of 472 individuals combined from 480 from the
baseline data set and 487 individuals from the amyloid dataset.
